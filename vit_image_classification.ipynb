{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715cc129",
   "metadata": {},
   "source": [
    "# Vision Transformer (ViT) Image Classification\n",
    "\n",
    "This notebook demonstrates how to use the Hugging Face Transformers library to classify images using a pre-trained Vision Transformer (ViT) model.\n",
    "\n",
    "## About Vision Transformer\n",
    "The Vision Transformer (ViT) is a BERT-like transformer encoder model pretrained on ImageNet-21k (14M images, 21k classes) and fine-tuned on ImageNet (1M images, 1k classes) at resolution 224x224 pixels.\n",
    "\n",
    "For more information, see [the Hugging Face model page](https://huggingface.co/google/vit-base-patch16-224)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d484b",
   "metadata": {},
   "source": [
    "## 1. Set Up Environment\n",
    "\n",
    "First, let's install the necessary packages. Note that **you need to restart the kernel after this cell completes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f86afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70.63s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "*** Installation cell complete. PLEASE RESTART THE KERNEL NOW before running the next cell! ***\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries if not already installed\n",
    "# =========================================================================================================\n",
    "# CRITICAL STEP: AFTER RUNNING THIS CELL, YOU **MUST** RESTART THE KERNEL BEFORE PROCEEDING!\n",
    "#                 Failure to restart the kernel will result in 'ModuleNotFoundError' for PyTorch.\n",
    "#                 In VS Code: Click the 'Restart' button for the kernel, or run 'Restart Kernel' from the Command Palette.\n",
    "# =========================================================================================================\n",
    "%pip install torch torchvision torchaudio transformers pillow requests --quiet\n",
    "print(\"\\n*** Installation cell complete. PLEASE RESTART THE KERNEL NOW before running the next cell! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48809456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install required packages\n",
    "%pip install transformers pillow requests --quiet\n",
    "# We don't need to explicitly install PyTorch as transformers will automatically\n",
    "# install the CPU version if needed.\n",
    "\n",
    "print(\"\\n✅ Installation complete. RESTART THE KERNEL before continuing!\")\n",
    "\n",
    "# Verify PyTorch installation and CUDA availability\n",
    "# IMPORTANT: This cell should only be run AFTER restarting the kernel post-installation.\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"Successfully imported PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        if torch.cuda.device_count() > 0:\n",
    "            print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "            print(f\"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    else:\n",
    "        print(\"CUDA not available. PyTorch will run on CPU.\")\n",
    "    print(\"\\n*** PyTorch verification successful. You can proceed with the next cells. ***\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(f\"ERROR: FAILED to import PyTorch: {e}\")\n",
    "    print(\"This means PyTorch is NOT installed correctly in the kernel's environment OR the kernel was NOT restarted after installation.\")\n",
    "    print(\"Please RE-RUN THE INSTALLATION CELL (Cell 2), then **RESTART THE KERNEL**, and then RE-RUN THIS VERIFICATION CELL (Cell 3).\")\n",
    "    print(\"Subsequent cells WILL FAIL until PyTorch is correctly installed and imported.\")\n",
    "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during PyTorch verification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66316b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ViTImageProcessor, ViTForImageClassification\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# Print Python and library information\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Transformers library loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c7d51",
   "metadata": {},
   "source": [
    "# Additional imports\n",
    "import torch  # For tensor operations\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "## Load an image from the web\n",
    "We will use an image from the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab78433",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bcef9f",
   "metadata": {},
   "source": [
    "## Load the ViT processor and model\n",
    "We use the pre-trained `google/vit-base-patch16-224` model.\n",
    "\n",
    "# Step 3: Load and display an image from the web\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "\n",
    "try:\n",
    "    # Download the image\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(response.raw)\n",
    "    \n",
    "    # Display the image\n",
    "    display(image)  # This works in Jupyter notebooks\n",
    "    print(f\"Image size: {image.size}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fd1cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nViTForImageClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m processor = ViTImageProcessor.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mgoogle/vit-base-patch16-224\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mViTForImageClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mgoogle/vit-base-patch16-224\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/utils/import_utils.py:1840\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/utils/import_utils.py:1828\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1826\u001b[39m failed = [msg.format(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[32m   1827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1828\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nViTForImageClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbecdb4",
   "metadata": {},
   "source": [
    "## Preprocess the image and run inference\n",
    "We process the image and use the model to predict its class.\n",
    "\n",
    "# Step 4: Load the ViT processor and model\n",
    "try:\n",
    "    # Load the image processor\n",
    "    print(\"Loading ViT image processor...\")\n",
    "    processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "    \n",
    "    # Load the model\n",
    "    print(\"Loading ViT model...\")\n",
    "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "    \n",
    "    print(\"✅ Model and processor loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or processor: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd065d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Check if torch is available and select device\u001b[39;00m\n\u001b[32m      4\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Check if torch is available and select device\n",
    "# Ensure 'torch' is imported in an earlier cell (Cell 4 after these changes)\n",
    "try:\n",
    "    # Select device (CPU or GPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Prepare the image for the model\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    \n",
    "    # Print the result\n",
    "    predicted_class = model.config.id2label[predicted_class_idx]\n",
    "    confidence = logits.softmax(dim=-1)[0][predicted_class_idx].item()\n",
    "    \n",
    "    print(f\"✅ Prediction successfully completed!\")\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718fadc",
   "metadata": {},
   "source": [
    "## 6. Display Top Predictions\n",
    "\n",
    "Let's show the top 5 predictions with their confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Display top predictions\n",
    "try:\n",
    "    # Get probabilities with softmax\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)[0]\n",
    "    \n",
    "    # Get the top 5 predictions\n",
    "    top5_prob, top5_indices = torch.topk(probs, 5)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Top 5 Predictions:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Class':<30} | {'Confidence':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, (prob, idx) in enumerate(zip(top5_prob, top5_indices)):\n",
    "        class_name = model.config.id2label[idx.item()]\n",
    "        print(f\"{class_name:<30} | {prob.item():>10.2%}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying top predictions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed501701",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we successfully:\n",
    "1. Set up the environment\n",
    "2. Loaded an image from the web\n",
    "3. Used a pre-trained Vision Transformer (ViT) model from Hugging Face\n",
    "4. Processed the image and obtained classification results\n",
    "5. Displayed the top predictions\n",
    "\n",
    "The model is trained on the ImageNet dataset, which contains 1,000 classes of common objects and animals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
